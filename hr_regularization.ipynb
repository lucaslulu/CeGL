{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0720aaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/leuven/347/vsc34778/miniconda3/envs/EnvNN/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from maraboupy import Marabou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b84d8970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "from torchsummary import summary\n",
    "\n",
    "class BinaryClassification(nn.Module):\n",
    "    def __init__(self, input_dimension):\n",
    "        super().__init__()\n",
    "        self.linear_layer1 = nn.Linear(input_dimension, 32)\n",
    "        self.linear_layer2 = nn.Linear(32, 32)\n",
    "        self.linear_layer3 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_dimension):\n",
    "        x1 = self.relu(self.linear_layer1(input_dimension))\n",
    "        x2 = self.relu(self.linear_layer2(x1))\n",
    "        x3 = self.linear_layer3(x2)\n",
    "        output = self.sigmoid(x3)\n",
    "        return output\n",
    "\n",
    "def configure_loss_function():\n",
    "    return nn.BCELoss()\n",
    "\n",
    "def SBL_regularization(feature, outputs, label, multi_category, lb_dic, ub_dic, y_constraint):\n",
    "    _, input_dimension = feature.shape\n",
    "    prob_sum, I = torch.tensor(0.0), 0 \n",
    "    for index, x in enumerate(feature):\n",
    "        flag = True\n",
    "        for i, val in enumerate(x):\n",
    "            if i in multi_category.keys():\n",
    "                if val in range(multi_category[i]):\n",
    "                    continue\n",
    "                else:\n",
    "                    flag = False\n",
    "                    break     \n",
    "            else:\n",
    "                if val >= lb_dic[i] and val <= ub_dic[i]:\n",
    "                     continue\n",
    "                else:\n",
    "                    flag = False\n",
    "                    break      \n",
    "        \n",
    "        if flag == True:\n",
    "            if outputs[index] <= 0.5 and y_constraint == 0:\n",
    "                prob_sum += (1.0-outputs[index][0])\n",
    "                I += 1\n",
    "            elif outputs[index] >0.5 and y_constraint == 1:\n",
    "                prob_sum += outputs[index][0]\n",
    "                I += 1\n",
    "    if I == 0:\n",
    "        return torch.tensor(0.0)\n",
    "        \n",
    "    return torch.tensor(1.0) - (prob_sum / torch.tensor(I))\n",
    "\n",
    "def SL_regularization(feature, outputs, label, multi_category, lb_dic, ub_dic, y_constraint):\n",
    "    _, input_dimension = feature.shape\n",
    "    prob_sum, I = torch.tensor(0.0), 0 \n",
    "    for index, x in enumerate(feature):\n",
    "        flag = True\n",
    "        for i, val in enumerate(x):\n",
    "            if i in multi_category.keys():\n",
    "                if val in range(multi_category[i]):\n",
    "                    continue\n",
    "                else:\n",
    "                    flag = False\n",
    "                    break     \n",
    "            else:\n",
    "                if val >= lb_dic[i] and val <= ub_dic[i]:\n",
    "                     continue\n",
    "                else:\n",
    "                    flag = False\n",
    "                    break      \n",
    "        \n",
    "        if flag == True:\n",
    "            if outputs[index] <= 0.5 and y_constraint == 0:\n",
    "                prob_sum += torch.log(1.0-outputs[index][0])\n",
    "                I += 1\n",
    "            elif outputs[index] >0.5 and y_constraint == 1:\n",
    "                prob_sum += torch.log(outputs[index][0])\n",
    "                I += 1\n",
    "    if I == 0:\n",
    "        return torch.tensor(0.0)\n",
    "        \n",
    "    return torch.neg(prob_sum) / torch.tensor(I)\n",
    "\n",
    "def configure_optimizer(model):\n",
    "    return torch.optim.Adam(model.parameters())\n",
    "\n",
    "def full_gd(model, criterion, optimizer, train_loader, \n",
    "            multi_category, lb_dic, ub_dic, y_constraint,\n",
    "             n_epochs, lambda_c, option):\n",
    "\n",
    "    size_t = len(train_loader)\n",
    "    for it in range(n_epochs): \n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            \n",
    "            feature, label = data\n",
    "            \n",
    "            outputs = model(feature)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(outputs, label)\n",
    "            if option == 1:\n",
    "                penalty = SBL_regularization(feature, outputs, label, multi_category, lb_dic, ub_dic, y_constraint)\n",
    "                loss = loss + torch.tensor(lambda_c) * penalty\n",
    "            elif option == 0:\n",
    "                penalty = SL_regularization(feature, outputs, label, multi_category, lb_dic, ub_dic, y_constraint)\n",
    "                loss = loss + torch.tensor(lambda_c) * penalty\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        if (it + 1) % 50 == 0:\n",
    "            print('[%d] loss: %.3f' % (it + 1, running_loss / n_epochs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b91f3616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cf973d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fea5e308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diameter</th>\n",
       "      <th>weight</th>\n",
       "      <th>red</th>\n",
       "      <th>green</th>\n",
       "      <th>blue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.96</td>\n",
       "      <td>86.76</td>\n",
       "      <td>172</td>\n",
       "      <td>85</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.91</td>\n",
       "      <td>88.05</td>\n",
       "      <td>166</td>\n",
       "      <td>78</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.42</td>\n",
       "      <td>95.17</td>\n",
       "      <td>156</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.47</td>\n",
       "      <td>95.60</td>\n",
       "      <td>163</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.48</td>\n",
       "      <td>95.76</td>\n",
       "      <td>161</td>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   diameter  weight  red  green  blue\n",
       "0      2.96   86.76  172     85     2\n",
       "1      3.91   88.05  166     78     3\n",
       "2      4.42   95.17  156     81     2\n",
       "3      4.47   95.60  163     81     4\n",
       "4      4.48   95.76  161     72     9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"./citrus.csv\")\n",
    "\n",
    "df.name[df.name == 'orange'] = 0\n",
    "df.name[df.name == 'grapefruit'] = 1\n",
    "\n",
    "X = df.drop(['name'], axis = 1)\n",
    "y = df['name']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9795648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name             1\n",
      "diameter     16.45\n",
      "weight      261.51\n",
      "red            192\n",
      "green          116\n",
      "blue            56\n",
      "dtype: object\n",
      "name            0\n",
      "diameter     2.96\n",
      "weight      86.76\n",
      "red           115\n",
      "green          31\n",
      "blue            2\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.max(axis=0))\n",
    "print(df.min(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aee6c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.21942179  0.04715308 -1.49350649  0.4875      0.14814815]]\n"
     ]
    }
   ],
   "source": [
    "sc = MinMaxScaler()\n",
    "sc.fit(X_train)\n",
    "print(sc.transform([[0,95,0,75,10]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9d3c0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def Correct_Accuracy(X, y_pred, y_true, multi_category, lb_dic, ub_dic, y_constraint):\n",
    "    _, input_dimension = X.shape\n",
    "    total, score = len(X), 0 \n",
    "    count = 0\n",
    "    for index, x in enumerate(X):\n",
    "        flag = True\n",
    "        for i, val in enumerate(x):\n",
    "            if i in multi_category.keys():\n",
    "                if val in range(multi_category[i]):\n",
    "                    continue\n",
    "                else:\n",
    "                    flag = False\n",
    "                    break     \n",
    "            else:\n",
    "                if x[i] >= lb_dic[i] and x[i] <= ub_dic[i]:\n",
    "                     continue\n",
    "                else:\n",
    "                    flag = False\n",
    "                    break      \n",
    "        \n",
    "        if flag == True:\n",
    "            if y_pred[index][0] == y_constraint:\n",
    "                score += 1\n",
    "            else:\n",
    "                count += 1\n",
    "        else:\n",
    "            if y_pred[index][0] == y_true[index]:\n",
    "                score += 1\n",
    "    return score / total, count\n",
    "\n",
    "def full_model_training(X_train, y_train, X_test, y_test, multi_category, lb_dic, ub_dic, \n",
    "                        lb_dic_d, ub_dic_d, y_constraint, batch, lambda_arr, option):\n",
    "    _, input_dimension = X_train.shape\n",
    "    BATCH_SIZE = batch\n",
    "    \n",
    "    criterion = configure_loss_function()\n",
    "    \n",
    "    X_train_v, X_val, y_train_v, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=40)\n",
    "    sc = MinMaxScaler()\n",
    "    sc.fit(X_train_v)\n",
    "    X_train_sc = sc.transform(X_train_v)\n",
    "    X_val_sc = sc.transform(X_val)\n",
    "    X_test_sc = sc.transform(X_test)\n",
    "    \n",
    "    X_train_tensor = torch.from_numpy(X_train_sc.astype(np.float32))\n",
    "    X_test_tensor = torch.from_numpy(X_test_sc.astype(np.float32))\n",
    "    X_val_tensor = torch.from_numpy(X_val_sc.astype(np.float32))\n",
    "    y_train_tensor = torch.from_numpy(y_train_v.astype(np.float32)).reshape(-1, 1)\n",
    "    y_test_tensor = torch.from_numpy(y_test.astype(np.float32)).reshape(-1, 1)\n",
    "    y_val_tensor = torch.from_numpy(y_val.astype(np.float32)).reshape(-1, 1)\n",
    "    \n",
    "    dealDataSet = TensorDataset(X_train_tensor,y_train_tensor)\n",
    "    train_Loader = DataLoader(dataset=dealDataSet, batch_size=BATCH_SIZE,shuffle=True)\n",
    "    dealDataSet = TensorDataset(X_test_tensor,y_test_tensor)\n",
    "    test_Loader = DataLoader(dataset=dealDataSet, batch_size=BATCH_SIZE,shuffle=True)\n",
    "    dealDataSet = TensorDataset(X_val_tensor,y_val_tensor)\n",
    "    test_Loader = DataLoader(dataset=dealDataSet, batch_size=BATCH_SIZE,shuffle=True)\n",
    "    \n",
    "    del X_train_tensor\n",
    "    del y_train_tensor\n",
    "    \n",
    "    best_lambda = -1\n",
    "    best_acc = -1\n",
    "    for lambda_c in lambda_arr:\n",
    "        \n",
    "        model = BinaryClassification(input_dimension)\n",
    "        optimizer = configure_optimizer(model)\n",
    "        full_gd(model, criterion, optimizer, train_Loader, multi_category, lb_dic_d, ub_dic_d, y_constraint, n_epochs=50, \n",
    "                lambda_c=lambda_c, option=option)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            p_val = model(X_val_tensor)\n",
    "            p_val = (p_val.numpy() > 0.5)\n",
    "            correct_accuracy_test, count = Correct_Accuracy(X_val, p_val, y_val, multi_category, lb_dic, ub_dic, y_constraint)\n",
    "            \n",
    "            if best_lambda == -1:\n",
    "                best_lambda = lambda_c\n",
    "                best_acc = correct_accuracy_test\n",
    "            elif correct_accuracy_test > best_acc:\n",
    "                best_lambda = lambda_c\n",
    "                best_acc = correct_accuracy_test\n",
    "            \n",
    "        del model\n",
    "        del optimizer\n",
    "        \n",
    "    del X_val_tensor\n",
    "    del y_val_tensor \n",
    "    \n",
    "    print(\"best lambda: \", best_lambda)\n",
    "        \n",
    "    model = BinaryClassification(input_dimension)\n",
    "    optimizer = configure_optimizer(model)\n",
    "    full_gd(model, criterion, optimizer, train_Loader, multi_category, lb_dic_d, ub_dic_d, y_constraint, n_epochs=100, \n",
    "                lambda_c=best_lambda, option=option)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        p_test = model(X_test_tensor)\n",
    "        p_test = (p_test.numpy() > 0.5)\n",
    "  \n",
    "        test_acc = np.mean(y_test_tensor.numpy() == p_test)\n",
    "    \n",
    "        correct_accuracy_test, count_test = Correct_Accuracy(X_test, p_test, y_test, multi_category, lb_dic, ub_dic, y_constraint)\n",
    "    \n",
    "    return correct_accuracy_test, count_test, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b94fa498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def Regularization_training(X_train, y_train, X_test, y_test, \n",
    "                  multi_category, lb_dic, ub_dic, lb_dic_d, ub_dic_d, y_constraint,\n",
    "                 eps, batch, lambda_arr, option):\n",
    "    \n",
    "    train_size, input_dimension = X_train.shape\n",
    "    Correct_Acc_prev, Model_prev = 0, None\n",
    "    correct_acc_arr = []\n",
    "    \n",
    "    res_ca, count, cur_model = full_model_training(np.copy(X_train), np.copy(y_train), np.copy(X_test), np.copy(y_test),\n",
    "                       multi_category=multi_category, lb_dic = lb_dic, ub_dic = ub_dic, \n",
    "                                                   lb_dic_d = lb_dic_d, ub_dic_d = ub_dic_d, y_constraint=y_constraint, \n",
    "                                                     batch=batch, lambda_arr = lambda_arr, option = option)\n",
    "    \n",
    "    return cur_model, res_ca, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fac92960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50] loss: 0.639\n",
      "best lambda:  0.0\n",
      "[50] loss: 0.319\n",
      "[100] loss: 0.313\n",
      "[50] loss: 0.638\n",
      "best lambda:  0.0\n",
      "[50] loss: 0.317\n",
      "[100] loss: 0.309\n",
      "[50] loss: 0.633\n",
      "best lambda:  0.0\n",
      "[50] loss: 0.315\n",
      "[100] loss: 0.311\n",
      "[50] loss: 0.631\n",
      "best lambda:  0.0\n",
      "[50] loss: 0.319\n",
      "[100] loss: 0.313\n",
      "[50] loss: 0.635\n",
      "best lambda:  0.0\n",
      "[50] loss: 0.317\n",
      "[100] loss: 0.310\n",
      "[50] loss: 0.640\n",
      "best lambda:  0.0\n",
      "[50] loss: 0.313\n",
      "[100] loss: 0.306\n",
      "[50] loss: 0.630\n",
      "best lambda:  0.0\n",
      "[50] loss: 0.316\n",
      "[100] loss: 0.313\n",
      "[50] loss: 0.637\n",
      "best lambda:  0.0\n",
      "[50] loss: 0.319\n",
      "[100] loss: 0.312\n",
      "[50] loss: 0.637\n",
      "best lambda:  0.0\n",
      "[50] loss: 0.318\n",
      "[100] loss: 0.311\n",
      "[50] loss: 0.629\n",
      "best lambda:  0.0\n",
      "[50] loss: 0.314\n",
      "[100] loss: 0.307\n",
      "[50] loss: 0.640\n",
      "best lambda:  0.0\n",
      "[50] loss: 0.318\n",
      "[100] loss: 0.311\n",
      "[50] loss: 0.625\n",
      "best lambda:  0.0\n",
      "[50] loss: 0.315\n",
      "[100] loss: 0.309\n",
      "[50] loss: 0.634\n",
      "best lambda:  0.0\n",
      "[50] loss: 0.317\n",
      "[100] loss: 0.312\n",
      "[50] loss: 0.628\n",
      "best lambda:  0.0\n",
      "[50] loss: 0.319\n",
      "[100] loss: 0.310\n",
      "[50] loss: 0.634\n",
      "best lambda:  0.0\n",
      "[50] loss: 0.320\n",
      "[100] loss: 0.312\n",
      "[50] loss: 0.637\n",
      "best lambda:  0.0\n",
      "[50] loss: 0.317\n",
      "[100] loss: 0.309\n",
      "[50] loss: 0.635\n",
      "best lambda:  0.0\n",
      "[50] loss: 0.316\n",
      "[100] loss: 0.310\n",
      "[50] loss: 0.633\n",
      "best lambda:  0.0\n",
      "[50] loss: 0.317\n",
      "[100] loss: 0.308\n",
      "[50] loss: 0.632\n",
      "best lambda:  0.0\n",
      "[50] loss: 0.317\n",
      "[100] loss: 0.312\n",
      "[50] loss: 0.634\n",
      "best lambda:  0.0\n",
      "[50] loss: 0.315\n",
      "[100] loss: 0.307\n"
     ]
    }
   ],
   "source": [
    "eps = 1e-5\n",
    "multi_category = { }\n",
    "lb_dic = { \n",
    "    0:2.0,\n",
    "    1:100.0,\n",
    "    2:0.0,\n",
    "    3:75.0,\n",
    "    4:10.0\n",
    "}\n",
    "ub_dic = { \n",
    "    0:20.0,\n",
    "    1:300.0,\n",
    "    2:255.0,\n",
    "    3:255.0,\n",
    "    4:255.0\n",
    "}\n",
    "\n",
    "lb_dic_d = { \n",
    "    0:0.0,\n",
    "    1:0.02904,\n",
    "    2:0.0,\n",
    "    3:0.51765,\n",
    "    4:1.7778e-1\n",
    "}\n",
    "ub_dic_d = { \n",
    "    0:1.0,\n",
    "    1:1.0,\n",
    "    2:1.0,\n",
    "    3:1.0,\n",
    "    4:1.0\n",
    "}\n",
    "\n",
    "y_constraint = 1\n",
    "lambda_arr = [0.0]\n",
    "batch = 32\n",
    "option = 1\n",
    "\n",
    "ca_arr = []\n",
    "count_arr = []\n",
    "\n",
    "while len(ca_arr) != 20:\n",
    "    model, Correct_Acc, count = Regularization_training(np.copy(X_train), np.copy(y_train), np.copy(X_test), np.copy(y_test),\n",
    "                  multi_category = multi_category, lb_dic = lb_dic, ub_dic = ub_dic, \n",
    "                                                        lb_dic_d = lb_dic_d, ub_dic_d = ub_dic_d, y_constraint=y_constraint, \n",
    "                   eps = eps, batch = batch, lambda_arr = lambda_arr, option = option)\n",
    "\n",
    "    ca_arr.append(Correct_Acc)\n",
    "    count_arr.append(count)\n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02073beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8468, 0.84, 0.8428, 0.8404, 0.8472, 0.8396, 0.8456, 0.8388, 0.8372, 0.8468, 0.8444, 0.8396, 0.8468, 0.8428, 0.844, 0.8468, 0.8376, 0.8412, 0.8412, 0.8392]\n",
      "[277, 295, 290, 295, 278, 298, 282, 300, 303, 286, 284, 297, 275, 289, 287, 277, 301, 292, 293, 296]\n"
     ]
    }
   ],
   "source": [
    "print(ca_arr)\n",
    "print(count_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4445309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baefbf13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
